- scheduling start...
- proceed to the experiment...


PTB-INFO: This is Psychtoolbox-3 for Microsoft Windows, under Matlab 64-Bit (Version 3.0.18 - Build date: Oct  3 2021).
PTB-INFO: OS support status: Windows 7 (Version 6.1) partially supported, but no longer tested at all.
PTB-INFO: Type 'PsychtoolboxVersion' for more detailed version information.
PTB-INFO: Most parts of the Psychtoolbox distribution are licensed to you under terms of the MIT License, with
PTB-INFO: some restrictions. See file 'License.txt' in the Psychtoolbox root folder for the exact licensing conditions.

PTB-INFO: For information about paid priority support, community membership and commercial services, please type
PTB-INFO: 'PsychPaidSupportAndServices'.

PTB-INFO: Will disable DWM because a regular fullscreen onscreen window is opened -> We want best timing and performance.
PTB-INFO: The detected endline of the vertical blank interval is equal or lower than the startline. This indicates
PTB-INFO: that i couldn't detect the duration of the vertical blank interval and won't be able to correct timestamps
PTB-INFO: for it. This will introduce a very small and constant offset (typically << 1 msec). Read 'help BeampositionQueries'
PTB-INFO: for how to correct this, should you really require that last few microseconds of precision.
PTB-INFO: Btw. this can also mean that your systems beamposition queries are slightly broken. It may help timing precision to
PTB-INFO: enable the beamposition workaround, as explained in 'help ConserveVRAMSettings', section 'kPsychUseBeampositionQueryWorkaround'.


PTB-INFO: OpenGL-Renderer is NVIDIA Corporation :: Quadro FX 3800/PCIe/SSE2 :: 3.3.0
PTB-INFO: VBL startline = 600 , VBL Endline = 599
PTB-INFO: Measured monitor refresh interval from beamposition = 16.596141 ms [60.254973 Hz].
PTB-INFO: Will use beamposition query for accurate Flip time stamping.
PTB-INFO: Measured monitor refresh interval from VBLsync = 16.596075 ms [60.255211 Hz]. (50 valid samples taken, stddev=0.008022 ms.)
PTB-INFO: Reported monitor refresh interval from operating system = 16.666667 ms [60.000000 Hz].
PTB-INFO: Small deviations between reported values are normal and no reason to worry.
line:562, trial=1, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=2, scenario=2, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=3, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=8 state= 3, 9 actions=1, 1
line:562, trial=4, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=5, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=6, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=0, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=7, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.270000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=8, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=1.730000e+01, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=9, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=1.260000e+01, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=10, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5


PTB-INFO: There are still 176 textures, offscreen windows or proxy windows open. Screen('CloseAll') will auto-close them.
PTB-INFO: This may be fine for studies where you only use a few textures or windows, but a large number of open
PTB-INFO: textures or offscreen windows can be an indication that you forgot to dispose no longer needed items
PTB-INFO: via a proper call to Screen('Close', [windowOrTextureIndex]); , e.g., at the end of each trial. These
PTB-INFO: stale objects linger around and can consume significant memory ressources, causing degraded performance,
PTB-INFO: timing trouble (if the system has to resort to disk paging) and ultimately out of memory conditions or
PTB-INFO: crashes. Please check your code. (Screen('Close') is a quick way to release all textures and offscreen windows)



INFO: PTB's Screen('Flip', 10) command seems to have missed the requested stimulus presentation deadline
INFO: a total of 4 times out of a total of 58 flips during this session.

INFO: This number is fairly accurate (and indicative of real timing problems in your own code or your system)
INFO: if you provided requested stimulus onset times with the 'when' argument of Screen('Flip', window [, when]);
INFO: If you called Screen('Flip', window); without the 'when' argument, this count is more of a ''mild'' indicator
INFO: of timing behaviour than a hard reliable measurement. Large numbers may indicate problems and should at least
INFO: deserve your closer attention. Cfe. 'help SyncTrouble', the FAQ section at www.psychtoolbox.org and the
INFO: examples in the PDF presentation in PsychDocumentation/Psychtoolbox3-Slides.pdf for more info and timing tips.



WARNING: This session of your experiment was run by you with the setting Screen('Preference', 'SkipSyncTests', 1).
WARNING: This means that some internal self-tests and calibrations were skipped. Your stimulus presentation timing
WARNING: may have been wrong. This is fine for development and debugging of your experiment, but for running the real
WARNING: study, please make sure to set Screen('Preference', 'SkipSyncTests', 0) for maximum accuracy and reliability.
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
Error in function FillRect: 	Invalid Window (or Texture) Index provided: It doesn't correspond to an open window or texture.
Did you close it accidentally via Screen('Close') or Screen('CloseAll') ?
{다음 사용 중 오류가 발생함: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('Screen')" style="font-weight:bold">Screen</a>
Usage:

Screen('FillRect', windowPtr [,color] [,rect] )

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('SIMUL_arbitration_fmri_merged', 'C:\Users\dckim\Desktop\for_redistribution_files_only\SIMUL_arbitration_fmri_merged.m', 663)" style="font-weight:bold">SIMUL_arbitration_fmri_merged</a> (<a href="matlab: opentoline('C:\Users\dckim\Desktop\for_redistribution_files_only\SIMUL_arbitration_fmri_merged.m',663,0)">line 663</a>)
            Screen('FillRect',wPtr,BackgroundColor_Cue_page);

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('task_main_2020', 'C:\Users\dckim\Desktop\for_redistribution_files_only\task_main_2020.m', 90)" style="font-weight:bold">task_main_2020</a> (<a href="matlab: opentoline('C:\Users\dckim\Desktop\for_redistribution_files_only\task_main_2020.m',90,0)">line 90</a>)
SIMUL_arbitration_fmri_merged(name, sess_num, sess_opt, image_num, 'real', input_scenario, input_seq,
cons,state_relo);
} 
task_main_2020
- scheduling start...
- scheduling start...
- proceed to the experiment...


PTB-INFO: This is Psychtoolbox-3 for Microsoft Windows, under Matlab 64-Bit (Version 3.0.18 - Build date: Oct  3 2021).
PTB-INFO: OS support status: Windows 7 (Version 6.1) partially supported, but no longer tested at all.
PTB-INFO: Type 'PsychtoolboxVersion' for more detailed version information.
PTB-INFO: Most parts of the Psychtoolbox distribution are licensed to you under terms of the MIT License, with
PTB-INFO: some restrictions. See file 'License.txt' in the Psychtoolbox root folder for the exact licensing conditions.

PTB-INFO: For information about paid priority support, community membership and commercial services, please type
PTB-INFO: 'PsychPaidSupportAndServices'.

PTB-INFO: Will disable DWM because a regular fullscreen onscreen window is opened -> We want best timing and performance.
PTB-INFO: The detected endline of the vertical blank interval is equal or lower than the startline. This indicates
PTB-INFO: that i couldn't detect the duration of the vertical blank interval and won't be able to correct timestamps
PTB-INFO: for it. This will introduce a very small and constant offset (typically << 1 msec). Read 'help BeampositionQueries'
PTB-INFO: for how to correct this, should you really require that last few microseconds of precision.
PTB-INFO: Btw. this can also mean that your systems beamposition queries are slightly broken. It may help timing precision to
PTB-INFO: enable the beamposition workaround, as explained in 'help ConserveVRAMSettings', section 'kPsychUseBeampositionQueryWorkaround'.


PTB-INFO: OpenGL-Renderer is NVIDIA Corporation :: Quadro FX 3800/PCIe/SSE2 :: 3.3.0
PTB-INFO: VBL startline = 600 , VBL Endline = 599
PTB-INFO: Measured monitor refresh interval from beamposition = 16.596368 ms [60.254147 Hz].
PTB-INFO: Will use beamposition query for accurate Flip time stamping.
PTB-INFO: Measured monitor refresh interval from VBLsync = 16.597459 ms [60.250187 Hz]. (50 valid samples taken, stddev=0.017446 ms.)
PTB-INFO: Reported monitor refresh interval from operating system = 16.666667 ms [60.000000 Hz].
PTB-INFO: Small deviations between reported values are normal and no reason to worry.
line:562, trial=1, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=2, scenario=2, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=3.210000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=3, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=7 state= 3, 9 actions=1, 2
line:562, trial=4, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=5, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=6, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=7, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=10, reward=0, condition=-1 state= 2, 8 actions=1, 1
line:562, trial=8, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 3, 9 actions=1, 2
line:562, trial=9, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 3, 9 actions=1, 1
line:562, trial=10, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=0, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=11, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=10, reward=10, condition=-1 state= 2, 8 actions=1, 1
line:562, trial=12, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 2, 9 actions=1, 2
line:562, trial=13, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.060000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=14, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=20, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=15, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=1.660000e+01, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=16, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=1.460000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=17, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=20, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=18, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=19, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=1.280000e+01, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=20, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=10, reward=10, condition=-1 state= 3, 8 actions=1, 1
line:562, trial=21, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=22, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.520000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=23, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=0, condition=8 state= 2, 7 actions=1, 1
line:562, trial=24, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=6 state= 5, 9 actions=2, 2
line:562, trial=25, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=31, condition=6 state= 4, 6 actions=2, 2
line:562, trial=26, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=27, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=28, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=-1 state= 2, 8 actions=1, 1
line:562, trial=29, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=30, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.830000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=31, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=10, reward=8.200000e+00, condition=8 state= 3, 8 actions=1, 1
line:562, trial=32, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.780000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=33, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.110000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=34, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 2, 8 actions=1, 1
line:562, trial=35, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=7 state= 3, 9 actions=1, 2
line:562, trial=36, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.610000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=37, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=-1 state= 2, 8 actions=1, 2
line:562, trial=38, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=39, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.690000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=40, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=41, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=42, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.860000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=43, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.260000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=44, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.820000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=45, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=46, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.440000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=47, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 2, 9 actions=1, 2
line:562, trial=48, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.550000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=49, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=50, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.410000e+01, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=51, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=52, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=13, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=53, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.240000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=54, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=-1 state= 3, 8 actions=1, 1
line:562, trial=55, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=12, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=56, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.340000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=57, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=-1 state= 3, 8 actions=1, 1
line:562, trial=58, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=59, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=8.500000e+00, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=60, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.120000e+01, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=61, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=62, scenario=4, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=8 state= 2, 8 actions=1, 2
line:562, trial=63, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=8.500000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=64, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 3, 8 actions=1, 1
line:562, trial=65, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=20, reward=0, condition=8 state= 3, 7 actions=1, 2
line:562, trial=66, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.390000e+01, condition=7 state= 3, 7 actions=1, 2
line:562, trial=67, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=5.600000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=68, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=0, condition=7 state= 4, 6 actions=2, 1
line:562, trial=69, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.810000e+01, condition=7 state= 3, 7 actions=1, 2
line:562, trial=70, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.460000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=71, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=8.700000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=72, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=8 state= 2, 8 actions=1, 2
line:562, trial=73, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 2, 8 actions=1, 1
line:562, trial=74, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.230000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=75, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=6 state= 4, 6 actions=2, 2
line:562, trial=76, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.520000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=77, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=8 state= 2, 9 actions=1, 2
line:562, trial=78, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=6 state= 4, 9 actions=2, 2
line:562, trial=79, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.140000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=80, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=8.100000e+00, condition=7 state= 2, 7 actions=1, 1


PTB-INFO: There are still 2234 textures, offscreen windows or proxy windows open. Screen('CloseAll') will auto-close them.
PTB-INFO: This may be fine for studies where you only use a few textures or windows, but a large number of open
PTB-INFO: textures or offscreen windows can be an indication that you forgot to dispose no longer needed items
PTB-INFO: via a proper call to Screen('Close', [windowOrTextureIndex]); , e.g., at the end of each trial. These
PTB-INFO: stale objects linger around and can consume significant memory ressources, causing degraded performance,
PTB-INFO: timing trouble (if the system has to resort to disk paging) and ultimately out of memory conditions or
PTB-INFO: crashes. Please check your code. (Screen('Close') is a quick way to release all textures and offscreen windows)



INFO: PTB's Screen('Flip', 10) command seems to have missed the requested stimulus presentation deadline
INFO: a total of 28 times out of a total of 831 flips during this session.

INFO: This number is fairly accurate (and indicative of real timing problems in your own code or your system)
INFO: if you provided requested stimulus onset times with the 'when' argument of Screen('Flip', window [, when]);
INFO: If you called Screen('Flip', window); without the 'when' argument, this count is more of a ''mild'' indicator
INFO: of timing behaviour than a hard reliable measurement. Large numbers may indicate problems and should at least
INFO: deserve your closer attention. Cfe. 'help SyncTrouble', the FAQ section at www.psychtoolbox.org and the
INFO: examples in the PDF presentation in PsychDocumentation/Psychtoolbox3-Slides.pdf for more info and timing tips.



WARNING: This session of your experiment was run by you with the setting Screen('Preference', 'SkipSyncTests', 1).
WARNING: This means that some internal self-tests and calibrations were skipped. Your stimulus presentation timing
WARNING: may have been wrong. This is fine for development and debugging of your experiment, but for running the real
WARNING: study, please make sure to set Screen('Preference', 'SkipSyncTests', 0) for maximum accuracy and reliability.
########################################################
### session3 is done ############################
### next session = 4 ############################
########################################################
- # of response failure in this session = 0. (will be penalized) 
state relo var : 2  4  5  1  3
