- now starting to organize the cue presentation files...
{다음 사용 중 오류가 발생함: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('copyfile')" style="font-weight:bold">copyfile</a>
일치하는 파일이 발견되지 않았습니다.

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('SIMUL_arbitration_fmri2_init', 'E:\for_redistribution_files_only_keyboad\SIMUL_arbitration_fmri2_init.m', 39)" style="font-weight:bold">SIMUL_arbitration_fmri2_init</a> (<a href="matlab: opentoline('E:\for_redistribution_files_only_keyboad\SIMUL_arbitration_fmri2_init.m',39,0)">line 39</a>)
    copyfile(src_file,dst_file,'f');    WaitSecs(0.3);

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('SIMUL_arbitration_fmri_merged', 'E:\for_redistribution_files_only_keyboad\SIMUL_arbitration_fmri_merged.m', 29)" style="font-weight:bold">SIMUL_arbitration_fmri_merged</a> (<a href="matlab: opentoline('E:\for_redistribution_files_only_keyboad\SIMUL_arbitration_fmri_merged.m',29,0)">line 29</a>)
        state_relo=SIMUL_arbitration_fmri2_init(case_num,state_relo);

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('task_main_2020', 'E:\for_redistribution_files_only_keyboad\task_main_2020.m', 90)" style="font-weight:bold">task_main_2020</a> (<a href="matlab: opentoline('E:\for_redistribution_files_only_keyboad\task_main_2020.m',90,0)">line 90</a>)
SIMUL_arbitration_fmri_merged(name, sess_num, sess_opt,
image_num, 'real', input_scenario, input_seq,
cons,state_relo);
} 
task_main_2020
- scheduling start...
- now starting to organize the cue presentation files...
{다음 사용 중 오류가 발생함: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('copyfile')" style="font-weight:bold">copyfile</a>
일치하는 파일이 발견되지 않았습니다.

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('SIMUL_arbitration_fmri2_init', 'E:\for_redistribution_files_only_keyboad\SIMUL_arbitration_fmri2_init.m', 39)" style="font-weight:bold">SIMUL_arbitration_fmri2_init</a> (<a href="matlab: opentoline('E:\for_redistribution_files_only_keyboad\SIMUL_arbitration_fmri2_init.m',39,0)">line 39</a>)
    copyfile(src_file,dst_file,'f');    WaitSecs(0.3);

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('SIMUL_arbitration_fmri_merged', 'E:\for_redistribution_files_only_keyboad\SIMUL_arbitration_fmri_merged.m', 29)" style="font-weight:bold">SIMUL_arbitration_fmri_merged</a> (<a href="matlab: opentoline('E:\for_redistribution_files_only_keyboad\SIMUL_arbitration_fmri_merged.m',29,0)">line 29</a>)
        state_relo=SIMUL_arbitration_fmri2_init(case_num,state_relo);

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('task_main_2020', 'E:\for_redistribution_files_only_keyboad\task_main_2020.m', 90)" style="font-weight:bold">task_main_2020</a> (<a href="matlab: opentoline('E:\for_redistribution_files_only_keyboad\task_main_2020.m',90,0)">line 90</a>)
SIMUL_arbitration_fmri_merged(name, sess_num, sess_opt,
image_num, 'real', input_scenario, input_seq,
cons,state_relo);
} 
task_main_2020
- scheduling start...
- now starting to organize the cue presentation files...
initialization completed.
- organization of the cue presentation files completed.
- scheduling start...
- proceed to the experiment...
PTB-WARNING: Startup test of beamposition queries for high precision timestamping detected problems on your graphics card + driver combo.
PTB-WARNING: Some of the queries fail even outside the vertical blank interval, so no effective workaround for this driver bug exists.
PTB-WARNING: This renders beamposition queries pretty useless -- Disabling high precision timestamping for now.
PTB-WARNING: Please report this message with a description of your graphics card, operating system and video driver to
PTB-WARNING: the Psychtoolbox forum. Maybe the gathered information allows for some work-around in
PTB-WARNING: future PTB releases to get high precision timestamping back on your setup.



PTB-INFO: This is Psychtoolbox-3 for Microsoft Windows, under Matlab 64-Bit (Version 3.0.18 - Build date: Feb  2 2022).
PTB-INFO: OS support status: Windows 10 (Version 10.0) supported and tested to some limited degree.
PTB-INFO: Type 'PsychtoolboxVersion' for more detailed version information.
PTB-INFO: Most parts of the Psychtoolbox distribution are licensed to you under terms of the MIT License, with
PTB-INFO: some restrictions. See file 'License.txt' in the Psychtoolbox root folder for the exact licensing conditions.

PTB-INFO: For information about paid priority support, community membership and commercial services, please type
PTB-INFO: 'PsychPaidSupportAndServices'.


PTB-WARNING: Couldn't determine end-line of vertical blanking interval for your display! Trouble with beamposition queries?!?
PTB-WARNING: Detected end-line is 600, which is either lower or more than 1.250000 times higher than vbl startline 750 --> Out of sane range!


PTB-INFO: OpenGL-Renderer is Intel :: Intel(R) UHD Graphics 620 :: 4.5.0 - Build 25.20.100.6577
PTB-INFO: VBL startline = 750 , VBL Endline = 600
PTB-INFO: Beamposition queries unsupported or defective on this system. Using basic timestamping as fallback.
PTB-INFO: Timestamps returned by Screen('Flip') will be therefore less robust and accurate.
PTB-INFO: Measured monitor refresh interval from VBLsync = 16.687936 ms [59.923528 Hz]. (50 valid samples taken, stddev=0.285115 ms.)
PTB-INFO: Reported monitor refresh interval from operating system = 16.666667 ms [60.000000 Hz].
PTB-INFO: Small deviations between reported values are normal and no reason to worry.
PTB-INFO: ==============================================================================================================================
PTB-INFO: WINDOWS DWM DESKTOP COMPOSITOR IS ACTIVE. On this Windows-10 or later system, Psychtoolbox can no longer reliably detect if
PTB-INFO: this will cause trouble for timing and integrity of visual stimuli or not. You might be just fine, or you could be in trouble.
PTB-INFO: Use external measurement equipment and independent procedures to verify reliability of timing if you care about proper timing.
PTB-INFO: ==============================================================================================================================

WARNING: Couldn't compute a reliable estimate of monitor refresh interval! Trouble with VBL syncing?!?


----- ! PTB - ERROR: SYNCHRONIZATION FAILURE ! -----

One or more internal checks (see Warnings above) indicate that synchronization
of Psychtoolbox to the vertical retrace (VBL) is not working on your setup.

This will seriously impair proper stimulus presentation and stimulus presentation timing!
Please read 'help SyncTrouble' for information about how to solve or work-around the problem.
You can force Psychtoolbox to continue, despite the severe problems, by adding the command
Screen('Preference', 'SkipSyncTests', 1); at the top of your script, if you really know what you are doing.




----- ! PTB - WARNING: SYNCHRONIZATION TROUBLE ! -----

One or more internal checks (see Warnings above) indicate that
queries of rasterbeam position are not properly working for your setup.

Psychtoolbox will work around this by using a different timing algorithm, 
but it will cause Screen('Flip') to report less accurate/robust timestamps
for stimulus timing.
Read 'help BeampositionQueries' for more info and troubleshooting tips.


line:562, trial=1, scenario=1, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=2, scenario=1, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=-1 state= 3, 8 actions=1, 1
line:562, trial=3, scenario=1, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.810000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=4, scenario=1, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.390000e+01, condition=-1 state= 3, 7 actions=1, 2
line:562, trial=5, scenario=1, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.130000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=6, scenario=1, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=9.300000e+00, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=7, scenario=1, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=8, scenario=1, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.350000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=9, scenario=1, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=6.600000e+00, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=10, scenario=1, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=5, condition=7 state= 4, 7 actions=2, 1
line:562, trial=11, scenario=1, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 2, 8 actions=1, 1
line:562, trial=12, scenario=1, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.440000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=13, scenario=1, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=0, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=14, scenario=1, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=7.200000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=15, scenario=1, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=5.200000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=16, scenario=1, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.040000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=17, scenario=1, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=4.900000e+00, condition=7 state= 2, 7 actions=1, 1
line:562, trial=18, scenario=1, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=4, condition=7 state= 2, 7 actions=1, 1
line:562, trial=19, scenario=1, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=0, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=20, scenario=1, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=3.600000e+00, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=21, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=22, scenario=2, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=23, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=6 state= 4, 9 actions=2, 2
line:562, trial=24, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=10, reward=0, condition=-1 state= 2, 8 actions=1, 2
line:562, trial=25, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=20, reward=0, condition=-1 state= 3, 7 actions=1, 2
line:562, trial=26, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 3, 9 actions=1, 2
line:562, trial=27, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=1.560000e+01, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=28, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=29, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=10, reward=7.500000e+00, condition=-1 state= 2, 8 actions=1, 1
line:562, trial=30, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 3, 9 actions=1, 2
line:562, trial=31, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=10, reward=8, condition=-1 state= 2, 8 actions=1, 1
line:562, trial=32, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=40, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=33, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.850000e+01, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=34, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=35, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=20, reward=1.630000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=36, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 1
line:562, trial=37, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.980000e+01, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=38, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=1.620000e+01, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=39, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=40, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.430000e+01, condition=-1 state= 4, 6 actions=2, 1
line:562, trial=41, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=42, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.520000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=43, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.870000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=44, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.820000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=45, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.530000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=46, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.610000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=47, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.890000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=48, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.610000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=49, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.910000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=50, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.340000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=51, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.790000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=52, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=53, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.580000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=54, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.220000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=55, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=56, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.720000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=57, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.790000e+01, condition=-1 state= 4, 6 actions=2, 1
line:562, trial=58, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=14, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=59, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=-1 state= 2, 8 actions=1, 2
line:562, trial=60, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.160000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=61, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=62, scenario=4, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=0, condition=8 state= 4, 6 actions=2, 2
line:562, trial=63, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=8 state= 2, 8 actions=1, 2
line:562, trial=64, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 3, 8 actions=1, 1
line:562, trial=65, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.740000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=66, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 2, 8 actions=1, 2
line:562, trial=67, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.420000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=68, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.780000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=69, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=8 state= 2, 8 actions=1, 2
line:562, trial=70, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=7.100000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=71, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=5.700000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=72, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=8 state= 3, 9 actions=1, 2
line:562, trial=73, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=7 state= 2, 7 actions=1, 1
line:562, trial=74, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=4.300000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=75, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=3.100000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=76, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.130000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=77, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.860000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=78, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.430000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=79, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.120000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=80, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.460000e+01, condition=7 state= 2, 7 actions=1, 1


PTB-INFO: There are still 2294 textures, offscreen windows or proxy windows open. Screen('CloseAll') will auto-close them.
PTB-INFO: This may be fine for studies where you only use a few textures or windows, but a large number of open
PTB-INFO: textures or offscreen windows can be an indication that you forgot to dispose no longer needed items
PTB-INFO: via a proper call to Screen('Close', [windowOrTextureIndex]); , e.g., at the end of each trial. These
PTB-INFO: stale objects linger around and can consume significant memory ressources, causing degraded performance,
PTB-INFO: timing trouble (if the system has to resort to disk paging) and ultimately out of memory conditions or
PTB-INFO: crashes. Please check your code. (Screen('Close') is a quick way to release all textures and offscreen windows)



WARNING: This session of your experiment was run by you with the setting Screen('Preference', 'SkipSyncTests', 1).
WARNING: This means that some internal self-tests and calibrations were skipped. Your stimulus presentation timing
WARNING: may have been wrong. This is fine for development and debugging of your experiment, but for running the real
WARNING: study, please make sure to set Screen('Preference', 'SkipSyncTests', 0) for maximum accuracy and reliability.
########################################################
### session1 is done ############################
### next session = 2 ############################
########################################################
- # of response failure in this session = 1. (will be penalized) 
state relo var : 2  4  5  1  3
