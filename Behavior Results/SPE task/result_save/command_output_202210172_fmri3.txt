- scheduling start...
- proceed to the experiment...


PTB-INFO: This is Psychtoolbox-3 for Microsoft Windows, under Matlab 64-Bit (Version 3.0.18 - Build date: Oct  3 2021).
PTB-INFO: OS support status: Windows 7 (Version 6.1) partially supported, but no longer tested at all.
PTB-INFO: Type 'PsychtoolboxVersion' for more detailed version information.
PTB-INFO: Most parts of the Psychtoolbox distribution are licensed to you under terms of the MIT License, with
PTB-INFO: some restrictions. See file 'License.txt' in the Psychtoolbox root folder for the exact licensing conditions.

PTB-INFO: For information about paid priority support, community membership and commercial services, please type
PTB-INFO: 'PsychPaidSupportAndServices'.

PTB-INFO: Will disable DWM because a regular fullscreen onscreen window is opened -> We want best timing and performance.
PTB-INFO: The detected endline of the vertical blank interval is equal or lower than the startline. This indicates
PTB-INFO: that i couldn't detect the duration of the vertical blank interval and won't be able to correct timestamps
PTB-INFO: for it. This will introduce a very small and constant offset (typically << 1 msec). Read 'help BeampositionQueries'
PTB-INFO: for how to correct this, should you really require that last few microseconds of precision.
PTB-INFO: Btw. this can also mean that your systems beamposition queries are slightly broken. It may help timing precision to
PTB-INFO: enable the beamposition workaround, as explained in 'help ConserveVRAMSettings', section 'kPsychUseBeampositionQueryWorkaround'.


PTB-INFO: OpenGL-Renderer is NVIDIA Corporation :: Quadro FX 3800/PCIe/SSE2 :: 3.3.0
PTB-INFO: VBL startline = 600 , VBL Endline = 599
PTB-INFO: Measured monitor refresh interval from beamposition = 16.596195 ms [60.254775 Hz].
PTB-INFO: Will use beamposition query for accurate Flip time stamping.
PTB-INFO: Measured monitor refresh interval from VBLsync = 16.597525 ms [60.249946 Hz]. (50 valid samples taken, stddev=0.013185 ms.)
PTB-INFO: Reported monitor refresh interval from operating system = 16.666667 ms [60.000000 Hz].
PTB-INFO: Small deviations between reported values are normal and no reason to worry.
line:562, trial=1, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=2, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.080000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=3, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=4, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.320000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=5, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=19, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=6, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.930000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=7, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.120000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=8, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.870000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=9, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.450000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=10, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=14, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=11, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.190000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=12, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.020000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=13, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.160000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=14, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=8.700000e+00, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=15, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=-1 state= 2, 8 actions=1, 1
line:562, trial=16, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.710000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=17, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.460000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=18, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.840000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=19, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.370000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=20, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=7.700000e+00, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=21, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=22, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=23, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.490000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=24, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=25, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.120000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=26, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=27, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=10, reward=0, condition=7 state= 2, 8 actions=1, 1
line:562, trial=28, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.580000e+01, condition=6 state= 5, 6 actions=2, 2
line:562, trial=29, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=30, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.230000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=31, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.660000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=32, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.430000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=33, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.620000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=34, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=35, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.840000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=36, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.690000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=37, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.240000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=38, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=6 state= 5, 9 actions=2, 2
line:562, trial=39, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.180000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=40, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=8.600000e+00, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=41, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=42, scenario=4, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=8 state= 2, 9 actions=1, 2
line:562, trial=43, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.140000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=44, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.780000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=45, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=7 state= 2, 7 actions=1, 1
line:562, trial=46, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=15, condition=7 state= 2, 7 actions=1, 1
line:562, trial=47, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.020000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=48, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.480000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=49, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=8 state= 2, 8 actions=1, 2
line:562, trial=50, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=7 state= 4, 7 actions=2, 1
line:562, trial=51, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.510000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=52, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.610000e+01, condition=7 state= 4, 7 actions=2, 1
line:562, trial=53, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=7.900000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=54, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.240000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=55, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=9.100000e+00, condition=6 state= 4, 6 actions=2, 2
line:562, trial=56, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=6.600000e+00, condition=6 state= 4, 6 actions=2, 2
line:562, trial=57, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=5.500000e+00, condition=6 state= 4, 6 actions=2, 2
line:562, trial=58, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.550000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=59, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
{위치 2의 인덱스가 배열 경계를 초과합니다(11을(를) 초과하지 않아야 함).

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('SIMUL_arbitration_fmri_merged', 'C:\Users\dckim\Desktop\for_redistribution_files_only\SIMUL_arbitration_fmri_merged.m', 954)" style="font-weight:bold">SIMUL_arbitration_fmri_merged</a> (<a href="matlab: opentoline('C:\Users\dckim\Desktop\for_redistribution_files_only\SIMUL_arbitration_fmri_merged.m',954,0)">line 954</a>)
            sx3=floor(NUM_MSG_SIZE(1,tmp_1st_digit+1)*disp_scale_goalimg/3);
            sy3=floor(NUM_MSG_SIZE(2,tmp_1st_digit+1)*disp_scale_goalimg);

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('task_main_2020', 'C:\Users\dckim\Desktop\for_redistribution_files_only\task_main_2020.m', 90)" style="font-weight:bold">task_main_2020</a> (<a href="matlab: opentoline('C:\Users\dckim\Desktop\for_redistribution_files_only\task_main_2020.m',90,0)">line 90</a>)
SIMUL_arbitration_fmri_merged(name, sess_num, sess_opt, image_num, 'real', input_scenario, input_seq,
cons,state_relo);
} 
PTB-INFO: Enforcing script abortion and restoring desktop by executing Screen('CloseAll') now!
PTB-INFO: Please ignore the false error message (INTERNAL PSYCHTOOLBOX ERROR) caused by this...


PTB-INFO: There are still 1437 textures, offscreen windows or proxy windows open. Screen('CloseAll') will auto-close them.
PTB-INFO: This may be fine for studies where you only use a few textures or windows, but a large number of open
PTB-INFO: textures or offscreen windows can be an indication that you forgot to dispose no longer needed items
PTB-INFO: via a proper call to Screen('Close', [windowOrTextureIndex]); , e.g., at the end of each trial. These
PTB-INFO: stale objects linger around and can consume significant memory ressources, causing degraded performance,
PTB-INFO: timing trouble (if the system has to resort to disk paging) and ultimately out of memory conditions or
PTB-INFO: crashes. Please check your code. (Screen('Close') is a quick way to release all textures and offscreen windows)



INFO: PTB's Screen('Flip', 10) command seems to have missed the requested stimulus presentation deadline
INFO: a total of 17 times out of a total of 529 flips during this session.

INFO: This number is fairly accurate (and indicative of real timing problems in your own code or your system)
INFO: if you provided requested stimulus onset times with the 'when' argument of Screen('Flip', window [, when]);
INFO: If you called Screen('Flip', window); without the 'when' argument, this count is more of a ''mild'' indicator
INFO: of timing behaviour than a hard reliable measurement. Large numbers may indicate problems and should at least
INFO: deserve your closer attention. Cfe. 'help SyncTrouble', the FAQ section at www.psychtoolbox.org and the
INFO: examples in the PDF presentation in PsychDocumentation/Psychtoolbox3-Slides.pdf for more info and timing tips.



WARNING: This session of your experiment was run by you with the setting Screen('Preference', 'SkipSyncTests', 1).
WARNING: This means that some internal self-tests and calibrations were skipped. Your stimulus presentation timing
WARNING: may have been wrong. This is fine for development and debugging of your experiment, but for running the real
WARNING: study, please make sure to set Screen('Preference', 'SkipSyncTests', 0) for maximum accuracy and reliability.
opentoline('C:\Users\dckim\Desktop\for_redistribution_files_only\SIMUL_arbitration_fmri_merged.m',954,0)
task_main_2020
- scheduling start...
- scheduling start...
- proceed to the experiment...


PTB-INFO: This is Psychtoolbox-3 for Microsoft Windows, under Matlab 64-Bit (Version 3.0.18 - Build date: Oct  3 2021).
PTB-INFO: OS support status: Windows 7 (Version 6.1) partially supported, but no longer tested at all.
PTB-INFO: Type 'PsychtoolboxVersion' for more detailed version information.
PTB-INFO: Most parts of the Psychtoolbox distribution are licensed to you under terms of the MIT License, with
PTB-INFO: some restrictions. See file 'License.txt' in the Psychtoolbox root folder for the exact licensing conditions.

PTB-INFO: For information about paid priority support, community membership and commercial services, please type
PTB-INFO: 'PsychPaidSupportAndServices'.

PTB-INFO: Will disable DWM because a regular fullscreen onscreen window is opened -> We want best timing and performance.
PTB-INFO: The detected endline of the vertical blank interval is equal or lower than the startline. This indicates
PTB-INFO: that i couldn't detect the duration of the vertical blank interval and won't be able to correct timestamps
PTB-INFO: for it. This will introduce a very small and constant offset (typically << 1 msec). Read 'help BeampositionQueries'
PTB-INFO: for how to correct this, should you really require that last few microseconds of precision.
PTB-INFO: Btw. this can also mean that your systems beamposition queries are slightly broken. It may help timing precision to
PTB-INFO: enable the beamposition workaround, as explained in 'help ConserveVRAMSettings', section 'kPsychUseBeampositionQueryWorkaround'.


PTB-INFO: OpenGL-Renderer is NVIDIA Corporation :: Quadro FX 3800/PCIe/SSE2 :: 3.3.0
PTB-INFO: VBL startline = 600 , VBL Endline = 599
PTB-INFO: Measured monitor refresh interval from beamposition = 16.596387 ms [60.254079 Hz].
PTB-INFO: Will use beamposition query for accurate Flip time stamping.
PTB-INFO: Measured monitor refresh interval from VBLsync = 16.596991 ms [60.251884 Hz]. (50 valid samples taken, stddev=0.018352 ms.)
PTB-INFO: Reported monitor refresh interval from operating system = 16.666667 ms [60.000000 Hz].
PTB-INFO: Small deviations between reported values are normal and no reason to worry.
line:562, trial=1, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=2, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=3, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=4, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=16, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=5, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=12, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=6, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=7, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.880000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=8, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.980000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=9, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.540000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=10, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=11, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=-1 state= 2, 8 actions=1, 2
line:562, trial=12, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=9.700000e+00, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=13, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.840000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=14, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.370000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=15, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=8.600000e+00, condition=-1 state= 3, 8 actions=1, 1
line:562, trial=16, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=7, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=17, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=7.800000e+00, condition=-1 state= 2, 8 actions=1, 2
line:562, trial=18, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=19, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.070000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=20, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=7.700000e+00, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=21, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=22, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.250000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=23, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=20, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=24, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=25, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=8 state= 2, 9 actions=1, 2
line:562, trial=26, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=8 state= 2, 8 actions=1, 2
line:562, trial=27, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=0, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=28, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.340000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=29, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=0, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=30, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.870000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=31, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.330000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=32, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=1.030000e+01, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=33, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=1.150000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=34, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=8.300000e+00, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=35, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=8.800000e+00, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=36, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=9.100000e+00, condition=-1 state= 4, 6 actions=2, 1
line:562, trial=37, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=6.600000e+00, condition=-1 state= 4, 7 actions=2, 1
line:562, trial=38, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 2, 9 actions=1, 2
line:562, trial=39, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=5.700000e+00, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=40, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=-1 state= 3, 8 actions=1, 1
line:562, trial=41, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=42, scenario=4, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=7 state= 3, 9 actions=1, 1
line:562, trial=43, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 2, 8 actions=1, 2
line:562, trial=44, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=7 state= 2, 7 actions=1, 1
line:562, trial=45, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=20, reward=0, condition=8 state= 3, 7 actions=1, 2
line:562, trial=46, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.890000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=47, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.110000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=48, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=7 state= 5, 9 actions=2, 1
line:562, trial=49, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 3, 8 actions=1, 1
line:562, trial=50, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.360000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=51, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=6 state= 2, 8 actions=1, 2
line:562, trial=52, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.050000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=53, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=8 state= 2, 8 actions=1, 2
line:562, trial=54, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=8.300000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=55, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=7, condition=8 state= 2, 8 actions=1, 2
line:562, trial=56, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.280000e+01, condition=7 state= 4, 7 actions=2, 1
line:562, trial=57, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=5.300000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=58, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 3, 8 actions=1, 1
line:562, trial=59, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.070000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=60, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=9.100000e+00, condition=7 state= 4, 7 actions=2, 1
line:562, trial=61, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=62, scenario=2, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=3.020000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=63, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.130000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=64, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=0, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=65, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=1.470000e+01, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=66, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=1.840000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=67, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=20, reward=1.180000e+01, condition=-1 state= 3, 7 actions=1, 2
line:562, trial=68, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 3, 9 actions=1, 2
line:562, trial=69, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=20, reward=1.010000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=70, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=8, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=71, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=72, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=1.390000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=73, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=5.900000e+00, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=74, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=10, reward=10, condition=-1 state= 2, 8 actions=1, 1
line:562, trial=75, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=20, reward=5.100000e+00, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=76, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=20, reward=3.700000e+00, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=77, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=3.400000e+00, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=78, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=79, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=80, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
{다음 사용 중 오류가 발생함: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('save')" style="font-weight:bold">save</a>
변수 'HIST_map_state_info_Tag'을(를) 찾을 수 없습니다.

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('SIMUL_arbitration_fmri_merged', 'C:\Users\dckim\Desktop\for_redistribution_files_only\SIMUL_arbitration_fmri_merged.m', 1179)" style="font-weight:bold">SIMUL_arbitration_fmri_merged</a> (<a href="matlab: opentoline('C:\Users\dckim\Desktop\for_redistribution_files_only\SIMUL_arbitration_fmri_merged.m',1179,0)">line 1179</a>)
save(file_name_sv,'HIST_event_info','HIST_event_info_Tag','HIST_behavior_info','HIST_behavior_info_Tag','HIST_block_condition','HIST_block_condition_Tag','HIST_map_state_info','HIST_map_state_info_Tag');

오류 발생: <a href="matlab:matlab.internal.language.introspective.errorDocCallback('task_main_2020', 'C:\Users\dckim\Desktop\for_redistribution_files_only\task_main_2020.m', 90)" style="font-weight:bold">task_main_2020</a> (<a href="matlab: opentoline('C:\Users\dckim\Desktop\for_redistribution_files_only\task_main_2020.m',90,0)">line 90</a>)
SIMUL_arbitration_fmri_merged(name, sess_num, sess_opt, image_num, 'real', input_scenario, input_seq,
cons,state_relo);
} 
PTB-INFO: Enforcing script abortion and restoring desktop by executing Screen('CloseAll') now!
PTB-INFO: Please ignore the false error message (INTERNAL PSYCHTOOLBOX ERROR) caused by this...


PTB-INFO: There are still 2171 textures, offscreen windows or proxy windows open. Screen('CloseAll') will auto-close them.
PTB-INFO: This may be fine for studies where you only use a few textures or windows, but a large number of open
PTB-INFO: textures or offscreen windows can be an indication that you forgot to dispose no longer needed items
PTB-INFO: via a proper call to Screen('Close', [windowOrTextureIndex]); , e.g., at the end of each trial. These
PTB-INFO: stale objects linger around and can consume significant memory ressources, causing degraded performance,
PTB-INFO: timing trouble (if the system has to resort to disk paging) and ultimately out of memory conditions or
PTB-INFO: crashes. Please check your code. (Screen('Close') is a quick way to release all textures and offscreen windows)



INFO: PTB's Screen('Flip', 10) command seems to have missed the requested stimulus presentation deadline
INFO: a total of 17 times out of a total of 831 flips during this session.

INFO: This number is fairly accurate (and indicative of real timing problems in your own code or your system)
INFO: if you provided requested stimulus onset times with the 'when' argument of Screen('Flip', window [, when]);
INFO: If you called Screen('Flip', window); without the 'when' argument, this count is more of a ''mild'' indicator
INFO: of timing behaviour than a hard reliable measurement. Large numbers may indicate problems and should at least
INFO: deserve your closer attention. Cfe. 'help SyncTrouble', the FAQ section at www.psychtoolbox.org and the
INFO: examples in the PDF presentation in PsychDocumentation/Psychtoolbox3-Slides.pdf for more info and timing tips.



WARNING: This session of your experiment was run by you with the setting Screen('Preference', 'SkipSyncTests', 1).
WARNING: This means that some internal self-tests and calibrations were skipped. Your stimulus presentation timing
WARNING: may have been wrong. This is fine for development and debugging of your experiment, but for running the real
WARNING: study, please make sure to set Screen('Preference', 'SkipSyncTests', 0) for maximum accuracy and reliability.
matlab.internal.language.introspective.errorDocCallback('SIMUL_arbitration_fmri_merged', 'C:\Users\dckim\Desktop\for_redistribution_files_only\SIMUL_arbitration_fmri_merged.m', 1179)
    HIST_map_state_info_Tag{1,1}='state - state used in the s1,s2,s3';
    HIST_map_state_info_Tag{1,2}='map - map used in the s1,s2,s3';

    
file_imgind_sv_name=[EXP_NAME '_info.mat'];
{'EXP_NAME'은(는) 정의되지 않은 함수 또는 변수입니다.
} 
uiimport('C:\Users\dckim\Desktop\for_redistribution_files_only\result_save\202210172_fmri_info.mat',1)
task_main_2020
- scheduling start...
- scheduling start...
- proceed to the experiment...


PTB-INFO: This is Psychtoolbox-3 for Microsoft Windows, under Matlab 64-Bit (Version 3.0.18 - Build date: Oct  3 2021).
PTB-INFO: OS support status: Windows 7 (Version 6.1) partially supported, but no longer tested at all.
PTB-INFO: Type 'PsychtoolboxVersion' for more detailed version information.
PTB-INFO: Most parts of the Psychtoolbox distribution are licensed to you under terms of the MIT License, with
PTB-INFO: some restrictions. See file 'License.txt' in the Psychtoolbox root folder for the exact licensing conditions.

PTB-INFO: For information about paid priority support, community membership and commercial services, please type
PTB-INFO: 'PsychPaidSupportAndServices'.

PTB-INFO: Will disable DWM because a regular fullscreen onscreen window is opened -> We want best timing and performance.
PTB-INFO: The detected endline of the vertical blank interval is equal or lower than the startline. This indicates
PTB-INFO: that i couldn't detect the duration of the vertical blank interval and won't be able to correct timestamps
PTB-INFO: for it. This will introduce a very small and constant offset (typically << 1 msec). Read 'help BeampositionQueries'
PTB-INFO: for how to correct this, should you really require that last few microseconds of precision.
PTB-INFO: Btw. this can also mean that your systems beamposition queries are slightly broken. It may help timing precision to
PTB-INFO: enable the beamposition workaround, as explained in 'help ConserveVRAMSettings', section 'kPsychUseBeampositionQueryWorkaround'.


PTB-INFO: OpenGL-Renderer is NVIDIA Corporation :: Quadro FX 3800/PCIe/SSE2 :: 3.3.0
PTB-INFO: VBL startline = 600 , VBL Endline = 599
PTB-INFO: Measured monitor refresh interval from beamposition = 16.596309 ms [60.254362 Hz].
PTB-INFO: Will use beamposition query for accurate Flip time stamping.
PTB-INFO: Measured monitor refresh interval from VBLsync = 16.596722 ms [60.252863 Hz]. (50 valid samples taken, stddev=0.015439 ms.)
PTB-INFO: Reported monitor refresh interval from operating system = 16.666667 ms [60.000000 Hz].
PTB-INFO: Small deviations between reported values are normal and no reason to worry.
line:562, trial=1, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=2, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=3, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=4, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.510000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=5, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.090000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=6, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.260000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=7, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=-1 state= 2, 8 actions=1, 1
line:562, trial=8, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.750000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=9, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.280000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=10, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 3, 9 actions=1, 1
line:562, trial=11, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=-1 state= 2, 8 actions=1, 2
line:562, trial=12, scenario=3, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.830000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=13, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.350000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=14, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.480000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=15, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=16, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.230000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=17, scenario=3, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=18, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.410000e+01, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=19, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=9.300000e+00, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=20, scenario=3, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=15, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=21, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=-1 state= 2, 7 actions=1, 1
line:562, trial=22, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=0, condition=6 state= 2, 7 actions=1, 1
line:562, trial=23, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=8 state= 2, 8 actions=1, 2
line:562, trial=24, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=7 state= 2, 7 actions=1, 1
line:562, trial=25, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.9         0.1
line:892, arrival=10, reward=0, condition=7 state= 3, 8 actions=1, 1
line:562, trial=26, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=1.640000e+01, condition=7 state= 2, 7 actions=1, 1
line:562, trial=27, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=6 state= 4, 6 actions=2, 2
line:562, trial=28, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=6.600000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=29, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=20, reward=18, condition=7 state= 4, 7 actions=2, 1
line:562, trial=30, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=0, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=31, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=1.590000e+01, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=32, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=33, scenario=5, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 3, 9 actions=1, 2
line:562, trial=34, scenario=5, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 3, 9 actions=1, 1
line:562, trial=35, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=8 state= 3, 9 actions=1, 1
line:562, trial=36, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=8 state= 2, 9 actions=1, 2
line:562, trial=37, scenario=5, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.560000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=38, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.550000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=39, scenario=5, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=40, scenario=5, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=41, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=42, scenario=4, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=3.540000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=43, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=7 state= 2, 7 actions=1, 1
line:562, trial=44, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=10, condition=8 state= 2, 8 actions=1, 2
line:562, trial=45, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=7.700000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=46, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.650000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=47, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=2.010000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=48, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=17, condition=6 state= 4, 6 actions=2, 2
line:562, trial=49, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=6.600000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=50, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=0, reward=0, condition=6 state= 5, 9 actions=2, 2
line:562, trial=51, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=4.800000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=52, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=6.200000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=53, scenario=4, policy=4
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.830000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=54, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=6.500000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=55, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=20, reward=20, condition=7 state= 2, 7 actions=1, 1
line:562, trial=56, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.540000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=57, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=5.800000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=58, scenario=4, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.9         0.1
line:892, arrival=10, reward=5.200000e+00, condition=8 state= 2, 8 actions=1, 2
line:562, trial=59, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.280000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=60, scenario=4, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=1.120000e+01, condition=6 state= 4, 6 actions=2, 2
line:562, trial=61, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.9         0.1
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.9         0.1
line:892, arrival=40, reward=40, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=62, scenario=2, policy=2
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=20, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=63, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=10, reward=0, condition=7 state= 2, 8 actions=1, 1
line:562, trial=64, scenario=2, policy=3
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 2,action 1 - state 7  8, action 2 -state 8  9, prob : 0.5         0.5
line:892, arrival=10, reward=7.800000e+00, condition=-1 state= 2, 8 actions=1, 1
line:562, trial=65, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=0, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=66, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=67, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=68, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=20, reward=1.640000e+01, condition=-1 state= 5, 7 actions=2, 1
line:562, trial=69, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=10, reward=6.900000e+00, condition=-1 state= 3, 8 actions=1, 1
line:562, trial=70, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 3,action 1 - state 8  9, action 2 -state 7  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 3, 9 actions=1, 2
line:562, trial=71, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=3.130000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=72, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=73, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.810000e+01, condition=-1 state= 4, 6 actions=2, 2
line:562, trial=74, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=75, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=76, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=3.030000e+01, condition=-1 state= 5, 6 actions=2, 2
line:562, trial=77, scenario=2, policy=5
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 2
line:562, trial=78, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 4, 9 actions=2, 2
line:562, trial=79, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 5,action 1 - state 7  9, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=0, reward=0, condition=-1 state= 5, 9 actions=2, 1
line:562, trial=80, scenario=2, policy=1
line 579: state - 1,action 1 - state 2  3, action 2 -state 4  5, prob : 0.5         0.5
line 579: state - 4,action 1 - state 6  7, action 2 -state 6  9, prob : 0.5         0.5
line:892, arrival=40, reward=2.190000e+01, condition=-1 state= 4, 6 actions=2, 2


PTB-INFO: There are still 2207 textures, offscreen windows or proxy windows open. Screen('CloseAll') will auto-close them.
PTB-INFO: This may be fine for studies where you only use a few textures or windows, but a large number of open
PTB-INFO: textures or offscreen windows can be an indication that you forgot to dispose no longer needed items
PTB-INFO: via a proper call to Screen('Close', [windowOrTextureIndex]); , e.g., at the end of each trial. These
PTB-INFO: stale objects linger around and can consume significant memory ressources, causing degraded performance,
PTB-INFO: timing trouble (if the system has to resort to disk paging) and ultimately out of memory conditions or
PTB-INFO: crashes. Please check your code. (Screen('Close') is a quick way to release all textures and offscreen windows)



INFO: PTB's Screen('Flip', 10) command seems to have missed the requested stimulus presentation deadline
INFO: a total of 26 times out of a total of 831 flips during this session.

INFO: This number is fairly accurate (and indicative of real timing problems in your own code or your system)
INFO: if you provided requested stimulus onset times with the 'when' argument of Screen('Flip', window [, when]);
INFO: If you called Screen('Flip', window); without the 'when' argument, this count is more of a ''mild'' indicator
INFO: of timing behaviour than a hard reliable measurement. Large numbers may indicate problems and should at least
INFO: deserve your closer attention. Cfe. 'help SyncTrouble', the FAQ section at www.psychtoolbox.org and the
INFO: examples in the PDF presentation in PsychDocumentation/Psychtoolbox3-Slides.pdf for more info and timing tips.



WARNING: This session of your experiment was run by you with the setting Screen('Preference', 'SkipSyncTests', 1).
WARNING: This means that some internal self-tests and calibrations were skipped. Your stimulus presentation timing
WARNING: may have been wrong. This is fine for development and debugging of your experiment, but for running the real
WARNING: study, please make sure to set Screen('Preference', 'SkipSyncTests', 0) for maximum accuracy and reliability.
########################################################
### session3 is done ############################
### next session = 4 ############################
########################################################
- # of response failure in this session = 0. (will be penalized) 
state relo var : 2  4  5  1  3
